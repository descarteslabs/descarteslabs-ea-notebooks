{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aff9c49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Searching and accessing data using the DL Enterprise Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18b346",
   "metadata": {},
   "source": [
    "In this notebook you will access data using the Scenes API. Streamlined data access is core to the DL Enterprise Accelerator. To demonstrate the basics of exploring and accessing data we will be constructing a cloud-free Sentinel-2 L2A NDVI composite over an area in the corn-belt of the United States (Iowa specifically). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88ed8e",
   "metadata": {},
   "source": [
    "We will use the following DL API's in this exercise:\n",
    "- [Scenes](https://docs.descarteslabs.com/descarteslabs/scenes/readme.html) - Query for and access imagery over our AOI\n",
    "- [Geo](https://docs.descarteslabs.com/descarteslabs/geo/readme.html) - Generate a DLTile aoi\n",
    "\n",
    "\n",
    "We will use the following external Python packages:\n",
    "- [rasterio](https://rasterio.readthedocs.io/en/latest/index.html) - CRS aware plotting\n",
    "- [affine](https://github.com/rasterio/affine) - Translate metadata returned from Scenes into usable Affine transform for plotting\n",
    "- [matplotlib.pyplot](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.html) - Plot imagery\n",
    "- [numpy](https://numpy.org/doc/stable/index.html) - Array/imagery operations and manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from rasterio.plot import show\n",
    "from affine import Affine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.config.get_settings().current_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b2e56",
   "metadata": {},
   "source": [
    "## Creating an AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c954b3",
   "metadata": {},
   "source": [
    "We start off by creating an area of interest using the `dl.geo` submodule. We can create a DLTile for a specific latitude and longitude. [A DLTile](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.DLTile) is a part of the tiling system used by DL to split up the surface of the Earth into manageable chunks for analysis. When creating a DLTile we must specify a resolution (in meters), a tilesize (in number of pixels at the given resolution), and a padding if desired (in pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a90e05-63c7-43be-9e5c-f1e37e8e0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = dl.geo.DLTile.from_latlon(35.8052, -91.5531, 10, 1024, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98612379-e37c-40b6-b3d6-c97f4049a342",
   "metadata": {},
   "source": [
    "Let's look at the tile object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3382e-ae78-4c69-8e59-37a63cf10570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e10d74-3516-47f0-a8e0-720f3fb280b2",
   "metadata": {},
   "source": [
    "The DLTile not only contains information about the resolution, tilesize, and pad but also has an associated coordinate reference system (crs), bounds, geometry, geotransform, and a proj4 string. All DLTiles are created using a UTM (universal transverse mercator) crs. If you would like to create an AOI with a custom geometry and crs then you can specify [an AOI instead](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.AOI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b9a2b",
   "metadata": {},
   "source": [
    "## Searching for imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066dec",
   "metadata": {},
   "source": [
    "With our DLTile ready we can now search for and access imagery using Scenes. We start by searching the available data products in the DL Data Catalog. We do this using `scenes.search_products`. You can filter this search by specifying several arguments. For more information please see [the docs here](https://docs.descarteslabs.com/descarteslabs/scenes/docs/search.html#descarteslabs.scenes._search.search_products)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bdc3c-8e5a-49c0-871c-dd32c630085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dl.scenes.search_products(text=\"Sentinel-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732bf0d5-744d-4a9b-a46b-11bf6d120ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83425ccb-0104-44db-a71a-efcade9a65da",
   "metadata": {},
   "source": [
    "We get back two results from our search. One data product for Sentinel-1 and another for Sentinel-2. We will be using the Sentinel-2 L2A data product. To search for data in that product we need to use the `scenes.search` function. There are a few other parameters we should specify to filter what imagery we would like to access when using that function:\n",
    "\n",
    "- product - A DL Catalog product string specifying which unique product we would like to access data from\n",
    "- start_datetime - The beginning of the date range we would like to find imagery in\n",
    "- end_datetime - The end of the date range we would like to find imagery in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"esa:sentinel-2:l2a:v1\"\n",
    "start_datetime = \"2019-03-01\"\n",
    "end_datetime = \"2019-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cef07-86d6-4524-a3a2-cd275114c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb6c2a",
   "metadata": {},
   "source": [
    "We can plug in our AOI, product, start and end datetimes to the `dl.scenes.search()` function to find imagery meeting the specified arguments. We also specify `limit=None` and `cloud_fraction=0.25` to allow us to access as many scenes as are available that have an overall cloud fraction less than or equal to 25%. Cloud fraction here means the percent of an image that is covered by clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes, ctx = dl.scenes.search(\n",
    "    tile,\n",
    "    products=product,\n",
    "    start_datetime=start_datetime,\n",
    "    end_datetime=end_datetime,\n",
    "    limit=None,\n",
    "    cloud_fraction=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65170287",
   "metadata": {},
   "source": [
    "We get a `SceneCollection` and `GeoContext` back from the `dl.scenes.search()` call. The `SceneCollection` object contains metadata about the scenes we queried and methods for accessing those scenes. The `GeoContext` has information about the CRS, resolution, bounds, and shape associated with the AOI we specified and the underlying imagery we queried. The `GeoContext` is used to specify what scale, coordinate system, and over what area we want our imagery to be resampled, transformed, and clipped to. By default a `dl.scenes.search()` call will return a `GeoContext` with the native resolution and coordinate system of the imagery we are accessing. You can adjust these components of the `GeoContext` using the `assign()` method. For this notebook we will use the native resolution and CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b22ef",
   "metadata": {},
   "source": [
    "A `SceneCollection` contains metadata about the query you made using `dl.scenes.search()` as well as a series of `Scenes` objects each with their own metadata and methods. We can access this metadata using `SceneCollection.properties` which will list the metadata/properties for each fo the collections individual `Scenes`. This is useful for extracting information like a list of acquisition dates for all the images we queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f46e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [key for key, scene in scenes.groupby(lambda x: x.properties.date.strftime(\"%Y-%m-%d\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094582a",
   "metadata": {},
   "source": [
    "A `SceneCollection` can also be filtered by the various properties of its constituent `Scenes`. This is done using `SceneCollection.filter()` and either a predicate string of the form \"properties.property\" or using a lambda function (lambda x: x.properties.property). `SceneCollection`s can also be grouped based on properties using the `SceneCollection.groupby()` method. We won't be filtering or grouping the scenes in our collection for the sake of simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c66b8",
   "metadata": {},
   "source": [
    "## Accessing imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28240404",
   "metadata": {},
   "source": [
    "Now that we have queried the available imagery we can access the actual raster data.\n",
    "\n",
    "A `Scene` has two methods for pulling an image locally:\n",
    "- `.ndarray()` - Pulls the image data into a 3D numpy.ndarray of shape *(n bands, xs, ys)*\n",
    "- `.download()` - Downloads the image data down into a .geotiff at a specified filepath\n",
    "\n",
    "A `SceneCollection` has a variety of methods that allow you to pull imagery into your local environment:\n",
    "- `.stack()` - Pulls each individual image in parallel and stacks them all into a 4D array of shape *(n images, n bands, xs, ys)*\n",
    "- `.mosaic()` - Pulls all images into a single 3D array where the values are populated using the \"top-most\" image in the collection (specified by the last image in the `SceneCollection`)\n",
    "- `.download()` - Downloads each image into a .geotiff in parallel\n",
    "- `download_modaic()` - Downloads a single mosaic into a .geotiff using the same logic as `.mosaic()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c283fc",
   "metadata": {},
   "source": [
    "We will be using `.stack()` to create a 4D array of our queried imagery. We need to specify a few arguments for this method. We specify which bands we want to access (in this case the red and near infrared bands). We also want the cloud mask band to remove any cloudy pixels from our final composite. We specify that we want to mosaic images from the same aquisition day using the `flatten` kwarg. This will mean that the output array will have shape *(time/day, n bands, xs, ys)*. We also want to have the `.stack()` call to return some raster metadata that we can use for plotting our raster data cleanly. The final thing we specify is our \"scaling\". For this example we want reflectance values between 0-1.0. To do this we set `scaling=\"physical\"`. For more info on scaling parameters please see [here](https://docs.descarteslabs.com/descarteslabs/scenes/docs/scene.html#descarteslabs.scenes.scene.Scene.scaling_parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"red\", \"nir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0fabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack, meta = scenes.stack(\n",
    "    bands+[\"cloud_mask\"],\n",
    "    ctx,\n",
    "    flatten=lambda x: x.properties.date.strftime(\"%Y-%m-%d\"),\n",
    "    raster_info=True,\n",
    "    scaling=\"physical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbcede",
   "metadata": {},
   "source": [
    "With our imagery now pulled locally into an ndarray we can proceed to mask out any cloud pixels and compute NDVI (Normalized Difference Vegetation Index; a representation of crop health). NDVI can be computed using\n",
    "**(nir-red)/(nir + red)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.mask = (stack.mask) | np.repeat((stack[:,-1].data==1)[:, np.newaxis], stack.shape[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6746679",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = stack[:,0]\n",
    "nir = stack[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (nir - red)/(nir + red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e92d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c087beb",
   "metadata": {},
   "source": [
    "We now build our maximum NDVI composite by using the `.max()` method on our stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ndvi = ndvi.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b112f2",
   "metadata": {},
   "source": [
    "As mentioned before we can pull some useful metadata from the returned raster_info to use for plotting with rasterio.plot.show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_str = f\"EPSG:{meta[0]['coordinateSystem']['epsg']}\"\n",
    "af_transform = Affine.from_gdal(*meta[0][\"geoTransform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "show(\n",
    "    max_ndvi,\n",
    "    transform=af_transform,\n",
    "    ax=ax\n",
    ")\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5938d155-817b-42af-bc7f-f2d10ada02cd",
   "metadata": {},
   "source": [
    "## ToDo:\n",
    "Add link to new Catalog - https://packaged-analytics.dev.aws.descarteslabs.com/datasets/esa:sentinel-2:l2a:v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcda20-145a-459f-ad26-be7d427a5b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
